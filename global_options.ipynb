{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4980c0-a8f0-410c-8eb0-284d550a958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Global options for analysis\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ[\"CORENLP_HOME\"] = \"C:/Users/wasti/Desktop/DataForImpact/Measuring-Corporate-Culture-Using-Machine-Learning/stanford-corenlp-4.5.2/\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Set\n",
    "\n",
    "# Hardware options\n",
    "N_CORES: int = 2  # max number of CPU cores to use\n",
    "RAM_CORENLP: str = \"8G\"  # max RAM allocated for parsing using CoreNLP; increase to speed up parsing\n",
    "PARSE_CHUNK_SIZE: int = 100 # number of lines in the input file to process uing CoreNLP at once. Increase on workstations with larger RAM (e.g. to 1000 if RAM is 64G)  \n",
    "\n",
    "# location of the CoreNLP models; use / to seperate folders\n",
    "DATA_FOLDER: str = \"data/\"\n",
    "MODEL_FOLDER: str = \"models/\" # will be created if does not exist\n",
    "OUTPUT_FOLDER: str = \"outputs/\" # will be created if does not exist; !!! WARNING: existing files will be removed !!!\n",
    "\n",
    "# Parsing and analysis options\n",
    "STOPWORDS: Set[str] = set(\n",
    "    Path(\"resources\", \"StopWords_Generic.txt\").read_text().lower().split()\n",
    ")  # Set of stopwords from https://sraf.nd.edu/textual-analysis/resources/#StopWords\n",
    "PHRASE_THRESHOLD: int = 10  # threshold of the phraser module (smaller -> more phrases)\n",
    "PHRASE_MIN_COUNT: int = 10  # min number of times a bigram needs to appear in the corpus to be considered as a phrase\n",
    "W2V_DIM: int = 300  # dimension of word2vec vectors\n",
    "W2V_WINDOW: int = 5  # window size in word2vec\n",
    "W2V_ITER: int = 20  # number of iterations in word2vec\n",
    "N_WORDS_DIM: int = 500  # max number of words in each dimension of the dictionary\n",
    "DICT_RESTRICT_VOCAB = None # change to a fraction number (e.g. 0.2) to restrict the dictionary vocab in the top 20% of most frequent vocab\n",
    "\n",
    "# Inputs for constructing the expanded dictionary\n",
    "DIMS: List[str] = [\"integrity\", \"teamwork\", \"innovation\", \"respect\", \"quality\"]\n",
    "SEED_WORDS: Dict[str, List[str]] = {\n",
    "    \"integrity\": [\n",
    "        \"integrity\",\n",
    "        \"ethic\",\n",
    "        \"ethical\",\n",
    "        \"accountable\",\n",
    "        \"accountability\",\n",
    "        \"trust\",\n",
    "        \"honesty\",\n",
    "        \"honest\",\n",
    "        \"honestly\",\n",
    "        \"fairness\",\n",
    "        \"responsibility\",\n",
    "        \"responsible\",\n",
    "        \"transparency\",\n",
    "        \"transparent\",\n",
    "    ],\n",
    "    \"teamwork\": [\n",
    "        \"teamwork\",\n",
    "        \"collaboration\",\n",
    "        \"collaborate\",\n",
    "        \"collaborative\",\n",
    "        \"cooperation\",\n",
    "        \"cooperate\",\n",
    "        \"cooperative\",\n",
    "    ],\n",
    "    \"innovation\": [\n",
    "        \"innovation\",\n",
    "        \"innovate\",\n",
    "        \"innovative\",\n",
    "        \"creativity\",\n",
    "        \"creative\",\n",
    "        \"create\",\n",
    "        \"passion\",\n",
    "        \"passionate\",\n",
    "        \"efficiency\",\n",
    "        \"efficient\",\n",
    "        \"excellence\",\n",
    "        \"pride\",\n",
    "    ],\n",
    "    \"respect\": [\n",
    "        \"respectful\",\n",
    "        \"talent\",\n",
    "        \"talented\",\n",
    "        \"employee\",\n",
    "        \"dignity\",\n",
    "        \"empowerment\",\n",
    "        \"empower\",\n",
    "    ],\n",
    "    \"quality\": [\n",
    "        \"quality\",\n",
    "        \"customer\",\n",
    "        \"customer_commitment\",\n",
    "        \"dedication\",\n",
    "        \"dedicated\",\n",
    "        \"dedicate\",\n",
    "        \"customer_expectation\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Create directories if not exist\n",
    "Path(DATA_FOLDER, \"processed\", \"parsed\").mkdir(parents=True, exist_ok=True)\n",
    "Path(DATA_FOLDER, \"processed\", \"unigram\").mkdir(parents=True, exist_ok=True)\n",
    "Path(DATA_FOLDER, \"processed\", \"bigram\").mkdir(parents=True, exist_ok=True)\n",
    "Path(DATA_FOLDER, \"processed\", \"trigram\").mkdir(parents=True, exist_ok=True)\n",
    "Path(MODEL_FOLDER, \"phrases\").mkdir(parents=True, exist_ok=True)\n",
    "Path(MODEL_FOLDER, \"phrases\").mkdir(parents=True, exist_ok=True)\n",
    "Path(MODEL_FOLDER, \"w2v\").mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_FOLDER, \"dict\").mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_FOLDER, \"scores\").mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_FOLDER, \"scores\", \"temp\").mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_FOLDER, \"scores\", \"word_contributions\").mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66978d00-0174-4645-929a-bb421bc17132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
